package ureca.practice.elasticsearchpractice.service;

import co.elastic.clients.elasticsearch._types.query_dsl.BoolQuery;
import co.elastic.clients.elasticsearch._types.query_dsl.TextQueryType;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.data.domain.Sort;
import org.springframework.data.elasticsearch.client.elc.NativeQuery;
import org.springframework.data.elasticsearch.core.ElasticsearchOperations;
import org.springframework.data.elasticsearch.core.SearchHit;
import org.springframework.data.elasticsearch.core.SearchHits;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;
import org.springframework.util.StringUtils;
import ureca.practice.elasticsearchpractice.document.TransactionFeedDocument;
import ureca.practice.elasticsearchpractice.dto.FeedDto;
import ureca.practice.elasticsearchpractice.entity.TransactionFeed;
import ureca.practice.elasticsearchpractice.repository.TransactionFeedRepository;
import ureca.practice.elasticsearchpractice.repository.TransactionFeedSearchRepository;

import java.util.regex.Matcher;
import java.util.regex.Pattern;
import java.util.stream.Collectors;

@Service
@RequiredArgsConstructor
@Slf4j
public class TransactionFeedService {

    private final TransactionFeedRepository feedRepository;
    private final TransactionFeedSearchRepository searchRepository;
    private final ElasticsearchOperations elasticsearchOperations;

    // "5gb", "5 GB", "5ê¸°ê°€" ë“±ì„ ëª¨ë‘ ì¡ì•„ë‚´ê¸° ìœ„í•œ ì •ê·œì‹
    private static final Pattern DATA_PATTERN = Pattern.compile("(\\d+)\\s*(gb|ê¸°ê°€|GB|mb|MB|ë©”ê°€)", Pattern.CASE_INSENSITIVE);


    // --- CRUD ---

    @Transactional
    public FeedDto.Response createFeed(FeedDto.Request request) {
        // 1. DBì— ì €ì¥
        TransactionFeed savedFeed = feedRepository.save(request.toEntity());

        // 2. Elasticsearchì— ì €ì¥ (ë°ì´í„° ë™ê¸°í™”)
        searchRepository.save(TransactionFeedDocument.from(savedFeed));

        return FeedDto.Response.from(savedFeed);
    }

    @Transactional(readOnly = true)
    public FeedDto.Response getFeed(String id) {
        TransactionFeed feed = feedRepository.findByTransactionFeedIdAndIsDeletedFalse(id)
                .orElseThrow(() -> new IllegalArgumentException("ê²Œì‹œê¸€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. id=" + id));
        return FeedDto.Response.from(feed);
    }

    @Transactional
    public FeedDto.Response updateFeed(String id, FeedDto.Request request) {
        // 1. DBì—ì„œ ì—”í‹°í‹° ì¡°íšŒ ë° ìˆ˜ì •
        TransactionFeed feed = feedRepository.findByTransactionFeedIdAndIsDeletedFalse(id)
                .orElseThrow(() -> new IllegalArgumentException("ê²Œì‹œê¸€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. id=" + id));
        feed.update(request.getTitle(), request.getContent(), request.getSalesPrice(), request.getSalesDataAmount(), request.getProgress());

        // 2. Elasticsearch ë°ì´í„° ì—…ë°ì´íŠ¸
        searchRepository.save(TransactionFeedDocument.from(feed));

        return FeedDto.Response.from(feed);
    }

    @Transactional
    public void deleteFeed(String id) {
        // 1. DBì—ì„œ ë…¼ë¦¬ì  ì‚­ì œ
        TransactionFeed feed = feedRepository.findByTransactionFeedIdAndIsDeletedFalse(id)
                .orElseThrow(() -> new IllegalArgumentException("ê²Œì‹œê¸€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. id=" + id));
        feed.delete();

        // 2. Elasticsearchì—ì„œ ë°ì´í„° ì‚­ì œ
        searchRepository.deleteById(id);
    }

    // --- Search ---

    // --- ìµœì¢… ì™„ì„±ëœ ê²€ìƒ‰ ë¡œì§ ---
    @Transactional(readOnly = true)
    public Page<FeedDto.Response> unifiedSearch(String rawQuery, Pageable pageable) {

        if (!StringUtils.hasText(rawQuery)) {
            return Page.empty(pageable);
        }

        // 1) "5gb, 500mb" íŒ¨í„´ ì¶”ì¶œ â†’ ì¿¼ë¦¬ ë¬¸ìì—´ì—ì„œ ì œê±°
        Matcher m = DATA_PATTERN.matcher(rawQuery);
        Long dataSizeMB = null;
        if (m.find()) {
            long size = Long.parseLong(m.group(1));
            String unit = m.group(2).toLowerCase();
            if (unit.matches("gb|ê¸°ê°€")) {
                dataSizeMB = size * 1000L;
            } else {
                dataSizeMB = size;
            }
//            rawQuery = m.replaceAll("").trim();
        }
        final String queryText = rawQuery;

        // ì—¬ëŸ¬ ì¡°ê±´ì„ ì¡°í•©í•˜ê¸° ìœ„í•´ BoolQuery.Builderë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        BoolQuery.Builder boolQueryBuilder = new BoolQuery.Builder();


        // 1. í…ìŠ¤íŠ¸ í•„ë“œì— ëŒ€í•œ multi_match ì¿¼ë¦¬ (í•­ìƒ ì‹¤í–‰)
        // 'should'ëŠ” OR ì¡°ê±´ê³¼ ìœ ì‚¬í•˜ê²Œ ë™ì‘í•˜ë©°, ë§ì´ ì¼ì¹˜í• ìˆ˜ë¡ ì ìˆ˜ê°€ ë†’ì•„ì§‘ë‹ˆë‹¤.
        boolQueryBuilder.should(s -> s
                .multiMatch(mm -> mm
                        .query(queryText)
                        .fields("title^3", "content", "sellerIdText", "telecomCompanyText") // ì œëª©ì—ëŠ” 3ë°°ì˜ ê°€ì¤‘ì¹˜ ë¶€ì—¬
                        .type(TextQueryType.BestFields)
                )
        );
        log.info("ğŸ‘½ğŸ‘½í…ìŠ¤íŠ¸");

        if (dataSizeMB != null) {
            long filterValue = dataSizeMB;
            boolQueryBuilder.filter(f -> f.term(t -> t
                    .field("salesDataAmount")
                    .value(filterValue)
                    .boost(2.0f)
            ));

            log.info("ğŸ‘½ğŸ‘½ìˆ«ì");

        }

        // 3. ìµœì¢… ì¿¼ë¦¬ ë¹Œë“œ
        NativeQuery query = NativeQuery.builder()
                .withQuery(q -> q.bool(boolQueryBuilder.build())) // bool ì¿¼ë¦¬ ì ìš©
                .withPageable(pageable)
                .withSort(Sort.by(Sort.Direction.DESC, "_score")) // 1. ì •í™•ë„ ìˆœ
                .withSort(Sort.by(Sort.Direction.DESC, "createdAt")) // 2. ìµœì‹ ìˆœ
                .build();

        // Elasticsearch ê²€ìƒ‰ ì‹¤í–‰
        SearchHits<TransactionFeedDocument> searchHits = elasticsearchOperations.search(query, TransactionFeedDocument.class);

        // Page ê°ì²´ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        Page<TransactionFeedDocument> page = org.springframework.data.support.PageableExecutionUtils.getPage(
                searchHits.getSearchHits().stream().map(SearchHit::getContent).collect(Collectors.toList()),
                pageable,
                searchHits::getTotalHits
        );

        return page.map(FeedDto.Response::from);
    }
}
